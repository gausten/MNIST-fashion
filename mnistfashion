# Koden har i första hand tagits från https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_classification.ipynb#scrollTo=2tRmdq_8CaXb
# Koden har sedan modifierats baserat på information från "deep learning with python"-boken och med information från websidan:

# TensorFlow och tf.keras
import tensorflow as tf
from tensorflow import keras

# Hjälpbibliotek
import numpy as np
import matplotlib.pyplot as plt

# Visa version av tensorflow
print(tf.__version__)

# Datasetet laddas ner här. (Det borde även gå att skriva "from keras.datasets import fashion_mnist".)
fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# train_images.shape visar hur många bilder det finns i träningssetet (60 000) och att de har 28 x 28 pixlar.
train_images.shape
# len(train_labels) visar hur många lables det finns i träningssetet (totalt 60 000 lables, en per bild)
len(train_labels)
# train_labels visar innehållet i train_labels, vilket är 60 000 siffror mellan 0 och 9.
train_labels

# motsvarande för test-setet:
test_images.shape
len(test_labels)
test_labels

# Här normaliseras gråskalan i bilderna till att gå från 0 till 1 istället för 0 till 255.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Här kommer det som spelar roll; hur vi väljer att bygga vårt neuronala nät. Det viktiga är att det avslutande lagret har 10 noder (motsvarande de 10 olika sorternas kläder som finns), och att det är ett softmaxlager (som ger sannolikheter som sammanlagt blir 1).
# Lager 1 är "convolution" med fönsterstorlek 5x5 och padding. Lager 2 är downsamplar det hela genom att använda en stride på 2.
# Lager 3 är som lager 1. 
model = keras.Sequential([
    keras.layers.Conv2D(32, (5, 5), padding="same", activation=tf.nn.relu, input_shape=(28, 28, 1)),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Conv2D(64, (5, 5), padding="same", activation=tf.nn.relu),
    keras.layers.MaxPooling2D((2, 2)),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])
train_images = train_images.reshape((60000, 28, 28, 1))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28, 28, 1))
test_images = test_images.astype('float32') / 255

# Här kan man se vad modellen har för arkitetktur.
model.summary()

# Här complieras modellen med optimeringsfunktion, förlustfunktion och monitoreringsfunktion. Dessa går också att ändra på lite...
model.compile(optimizer=tf.train.AdamOptimizer(), 
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Här tränas modellen. Epochs är antalet gånger som den får träna. Batch_size matchas med antalet neuron i näst sista lagret i modellen.
model.fit(train_images, train_labels, epochs=50, batch_size=64)

# Här får man se hur den klarar av själva testet.
test_loss, test_acc = model.evaluate(test_images, test_labels)

print('Test accuracy:', test_acc)
